{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping EDGAR for Financial Documents\n",
    "\n",
    "In this notebook, I will be writing code to retrieve 10K and 10Q reports from a given company, given their tickers. To run this, you will need to install the very powerful sec_edgar_downloader package via  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sec_edgar_downloader in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (4.2.2)\n",
      "Requirement already satisfied: lxml in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from sec_edgar_downloader) (4.4.1)\n",
      "Requirement already satisfied: Faker in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from sec_edgar_downloader) (8.10.1)\n",
      "Requirement already satisfied: bs4 in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from sec_edgar_downloader) (0.0.1)\n",
      "Requirement already satisfied: requests in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from sec_edgar_downloader) (2.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from Faker->sec_edgar_downloader) (2.8.0)\n",
      "Requirement already satisfied: text-unidecode==1.3 in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from Faker->sec_edgar_downloader) (1.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from bs4->sec_edgar_downloader) (4.8.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from requests->sec_edgar_downloader) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from requests->sec_edgar_downloader) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from requests->sec_edgar_downloader) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from requests->sec_edgar_downloader) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.4->Faker->sec_edgar_downloader) (1.12.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/lucaskrenn/opt/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->bs4->sec_edgar_downloader) (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install sec_edgar_downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was able to pull financial documents from all companies that submitted such documents via the SEC website. However, this was done manually via copy/paste. This is a step that would need to be automated if I were to extrapolate this to other sectors/industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sec_edgar_downloader import Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>Company</th>\n",
       "      <th>State/Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1053468</td>\n",
       "      <td>ABBOTT GREGORY</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1295721</td>\n",
       "      <td>ACE Aviation Holdings Inc.</td>\n",
       "      <td>A8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002819</td>\n",
       "      <td>AIR CANADA /QUEBEC/</td>\n",
       "      <td>A8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1110452</td>\n",
       "      <td>AIR FRANCE-KLM /FI</td>\n",
       "      <td>I0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>310454</td>\n",
       "      <td>AIR MIDWEST INC</td>\n",
       "      <td>KS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CIK                     Company State/Country\n",
       "0  1053468              ABBOTT GREGORY            CO\n",
       "1  1295721  ACE Aviation Holdings Inc.            A8\n",
       "2  1002819         AIR CANADA /QUEBEC/            A8\n",
       "3  1110452          AIR FRANCE-KLM /FI            I0\n",
       "4   310454             AIR MIDWEST INC            KS"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the file\n",
    "companies = pd.read_csv(\"company_list.csv\")\n",
    "companies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling Data From One Company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The company CIK can be used to scrape the data. I will demonstrate a quick example (American Airlines) prior to downloading the full list of companies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>Company</th>\n",
       "      <th>State/Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6201</td>\n",
       "      <td>American Airlines Group Inc.</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CIK                       Company State/Country\n",
       "19  6201  American Airlines Group Inc.            TX"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies[companies['Company'] == 'American Airlines Group Inc.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a downloader instance. If no argument is passed\n",
    "# to the constructor, the package will download filings to\n",
    "# the current working directory.\n",
    "dl = Downloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all 10-K filings for American Airlines (ticker: AAL) from 2000 onwards\n",
    "dl.get(\"10-K\", \"6201\", after=\"2000-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAL', '0000006201']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"sec-edgar-filings/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that in the file created by the package, company documents are organized by their tickers, even though the CIK was used in the request. This will be handy in the backtesting phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling Data From All Companies\n",
    "\n",
    "Now, we will pull the data from all the companies found in the .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIKs = companies[\"CIK\"]\n",
    "for cik in CIKs.values:\n",
    "    dl.get(\"10-K\", str(cik), after=\"2000-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000100517', '0001351548', '0000101001', 'AAL', '0001405419']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"sec-edgar-filings/\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the results actually contain the CIKs, so we will need to rename them to get a better idea of tickers. Luckily, there is a complete mapping that is easily downloaded from the following link:\n",
    "\n",
    "http://rankandfiled.com/#/data/tickers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
